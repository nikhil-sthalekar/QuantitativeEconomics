{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression Example, TensorFlow Integration with Julia Test\n",
    "# from - https://github.com/malmaud/TensorFlow.jl\n",
    "using TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×10 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮                      \n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "# Generating synthetic data\n",
    "\n",
    "x = randn(100, 50)\n",
    "w = randn(50, 10)\n",
    "y_prob = exp(x * w)\n",
    "y_prob ./= sum(y_prob, 2)\n",
    "\n",
    "#drawing from sample\n",
    "function draw(probs)\n",
    "    y = zeros(size(probs))\n",
    "    for i in 1:size(probs,1)\n",
    "        index = rand(Categorical(probs[i, :]))\n",
    "        y[i, index] = 1\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "y = draw(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Saver>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the Model\n",
    "\n",
    "sess = Session(Graph())\n",
    "X = placeholder(Float64)\n",
    "Y_obs = placeholder(Float64)\n",
    "\n",
    "variable_scope(\"logistic_model\", initializer = Normal(0, 0.001)) do\n",
    "    global W = get_variable(\"weights\", [50, 10], Float64)\n",
    "    global B = get_variable(\"bias\", [10], Float64)\n",
    "end\n",
    "\n",
    "Y = nn.softmax(X*W + B)\n",
    "Loss = -reduce_sum(log(Y).*Y_obs)\n",
    "optimizer = train.AdamOptimizer()\n",
    "minimize_op = train.minimize(optimizer, Loss)\n",
    "saver = train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching get_tensors(::TensorFlow.#initialize_all_variables)\u001b[0m\nClosest candidates are:\n  get_tensors(\u001b[1m\u001b[31m::TensorFlow.nn.rnn_cell.LSTMStateTuple\u001b[0m) at /home/nikhil/.julia/v0.5/TensorFlow/src/ops/rnn_cell.jl:65\n  get_tensors(\u001b[1m\u001b[31m::TensorFlow.IndexedSlices\u001b[0m) at /home/nikhil/.julia/v0.5/TensorFlow/src/run.jl:41\n  get_tensors(\u001b[1m\u001b[31m::Array{T,1}\u001b[0m) at /home/nikhil/.julia/v0.5/TensorFlow/src/run.jl:26\n  ...\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching get_tensors(::TensorFlow.#initialize_all_variables)\u001b[0m\nClosest candidates are:\n  get_tensors(\u001b[1m\u001b[31m::TensorFlow.nn.rnn_cell.LSTMStateTuple\u001b[0m) at /home/nikhil/.julia/v0.5/TensorFlow/src/ops/rnn_cell.jl:65\n  get_tensors(\u001b[1m\u001b[31m::TensorFlow.IndexedSlices\u001b[0m) at /home/nikhil/.julia/v0.5/TensorFlow/src/run.jl:41\n  get_tensors(\u001b[1m\u001b[31m::Array{T,1}\u001b[0m) at /home/nikhil/.julia/v0.5/TensorFlow/src/run.jl:26\n  ...\u001b[0m",
      "",
      " in get_tensors(::Array{TensorFlow.#initialize_all_variables,1}) at /home/nikhil/.julia/v0.5/TensorFlow/src/run.jl:28",
      " in run(::TensorFlow.Session, ::Array{TensorFlow.#initialize_all_variables,1}, ::Dict{Any,Any}) at /home/nikhil/.julia/v0.5/TensorFlow/src/run.jl:125",
      " in run at /home/nikhil/.julia/v0.5/TensorFlow/src/run.jl:161 [inlined]",
      " in run(::TensorFlow.Session, ::Function) at /home/nikhil/.julia/v0.5/TensorFlow/src/run.jl:169"
     ]
    }
   ],
   "source": [
    "#Running the training\n",
    "\n",
    "run(sess, initialize_all_variables)\n",
    "checkpoint_path = mktempdir()\n",
    "info(\"Checkpoint files saved in $checkpoint_path\")\n",
    "\n",
    "for epoch in 1:100\n",
    "    cur_loss, _ = run(sess, vcat(Loss, minimize_op), Dict(X=>x, Y_obs=>y))\n",
    "    println(@sprintf(\"Current loss is %.2f\", cur_loss))\n",
    "    train.save(saver, sess, joinpath(checkpoint_path, \"logistic\"), global_step=epoch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
